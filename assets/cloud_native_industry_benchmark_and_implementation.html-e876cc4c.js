import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as e,o as p,c as o,a as s,b as a,d as i,e as n}from"./app-b3d3ed0d.js";const h={},g=n('<h1 id="云原生业界对标-落地实践" tabindex="-1"><a class="header-anchor" href="#云原生业界对标-落地实践" aria-hidden="true">#</a> 云原生业界对标 &amp; 落地实践</h1><p>Clay、腾讯、字节、美团、滴滴、Vivo等各大公司云原生落地实践 整理汇总</p><h2 id="clay-1" tabindex="-1"><a class="header-anchor" href="#clay-1" aria-hidden="true">#</a> Clay<sup>[1]</sup></h2><h3 id="企业落地云原生的目的" tabindex="-1"><a class="header-anchor" href="#企业落地云原生的目的" aria-hidden="true">#</a> 企业落地云原生的目的</h3><p>一句话概括：<strong>在保证稳定性的前提下，降本增效</strong></p><h3 id="云原生能力全景图" tabindex="-1"><a class="header-anchor" href="#云原生能力全景图" aria-hidden="true">#</a> 云原生能力全景图</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/2025k8s01.png" alt=""></p><h3 id="推广方法论" tabindex="-1"><a class="header-anchor" href="#推广方法论" aria-hidden="true">#</a> 推广方法论</h3><p>1）项目立项，确定目标，从上到下，从下到上，一同发力。</p><p>2）目标拆解，具体到各负责人，建立双周会，定期沟通同步进展。</p><p>3）先搞出个试点，最佳实践，然后 点--&gt; 线--&gt; 面 推广。</p><p>4）风险可控：采取小步快跑，敬畏生产的策略。</p><p>Work --&gt; Test --&gt; UT --&gt; Prod 灰度 --&gt; Prod 全量； 非核心--&gt;核心；提前制定好应急方案。</p><h2 id="腾讯-2" tabindex="-1"><a class="header-anchor" href="#腾讯-2" aria-hidden="true">#</a> 腾讯<sup>[2]</sup></h2><h3 id="这场技术改造-难点在哪里" tabindex="-1"><a class="header-anchor" href="#这场技术改造-难点在哪里" aria-hidden="true">#</a> 这场技术改造，难点在哪里？</h3><p>全面上云腾讯不是第一家，但腾讯是拥有最复杂的业务场景的一家，在这个过程中，需要结合业务制定各种各样的技术方案，来满足不同的业务诉求。</p><p>在自研业务上云之前，腾讯的每一个业务都有自己完整的技术栈，内部业务在一定程度上形成了“部门墙”效应。这样的改造，过程中既有高层的推进、动员，也有执行层的博弈、妥协，最终实现了用一个点调动全局，让全公司的技术团队得到了一次很好的穿透对齐，让分散的技术能力得以统一。</p><h3 id="像下一盘棋" tabindex="-1"><a class="header-anchor" href="#像下一盘棋" aria-hidden="true">#</a> “像下一盘棋”</h3><p>2018 年底腾讯开了一次高层决策会议，决定将公司内部所有平台合到一起推行 K8s，开始进行彻底的技术更新换代。</p><p>这个事情一开始由邹辉领导的 TKE 团队牵头。TKE 团队主要由一批资深技术人员构成，成员基本都在 30 岁以上，资历以 10 级、11 级为主，团队对成员的技术能力和业务理解能力要求很高。</p><p>现在要将所有东西都统一到标准的公有云 TKE 上去，其实内部技术团队难免会心生疑惑：你们是不是要过来抢我们的活？</p><p>制定了开源协同技术战略，把公司内部所有做相似事情的团队整合在一起，采取类似于外部开源运作的方式协同工作。这样既解决了技术浪费的问题，又可以去中心化，保持快速响应，还能更好地满足业务需求。</p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212112227266.png" alt=""></p><p>在解决了技术团队的顾虑之后，腾讯从高层开始推进，说服自研业务团队上云，同时打通职级晋升体系，通过设置公司级的专项大奖、普及云原生知识、改造进度榜单晾晒等，从多个方面入手提高大家积极性，依照三年规划，有步骤地进行云原生改造和上云。</p><h3 id="腾讯云原生底座的-养成-计划" tabindex="-1"><a class="header-anchor" href="#腾讯云原生底座的-养成-计划" aria-hidden="true">#</a> 腾讯云原生底座的“养成”计划</h3><p>TKE 平台在初期选择的更多还是一些<strong>无状态</strong>的业务，先让这些无状态的业务能够快速搬到云上完成改造。</p><p>腾讯自研业务需要满足<strong>灰度发布</strong>的要求。</p><p>同时 TKE 也给业务提供了一些虚拟机提供不了的能力，比如<strong>动态路由</strong>能力。</p><p>另外一个好处则是<strong>弹性伸缩和健康感知。</strong></p><p>还有就是<strong>成本</strong>上的优势。</p><p><strong>提高镜像分发的效率</strong>，不仅仅是有益于游戏场景。在一些 AI 训练场景中，镜像甚至更大，几十 GB 也不少见。</p><p>另一个不得不提的是<strong>原地升级</strong>的能力。</p><p>这么一个指标去做<strong>一键扩缩容</strong>的功能。</p><h3 id="深水区的那些痛" tabindex="-1"><a class="header-anchor" href="#深水区的那些痛" aria-hidden="true">#</a> 深水区的那些痛</h3><p>腾讯花了一年半的时间，将无状态业务搬到了云原生平台，几乎把能踩的坑都踩了一遍，为后续其他业务上云铺平了道路。</p><p>同时在一些业务层面，一些<strong>有状态的业务</strong>，比如说像 Redis 数据库、中间件、一些大数据的套件，也做了原生改造，逐步搬到了整个云原生平台上来。</p><p>在这个过程中，TKE 团队在<strong>调度层面</strong>做了大量的工作。</p><p><strong>沉淀多集群管理能力</strong></p><p>最近整个社区，包括腾讯主要投入做多集群的管理。单集群做得更小，比如说两千个节点，甚至几百个节点就行；但是让更多的集群组合在一起，通过多集群的调度管理，让它看起来像一个集群，通过这种方式去扩展整个底层资源池的规模。</p>',39),c={href:"https://cloud.tencent.com/developer/article/1899865",target:"_blank",rel:"noopener noreferrer"},l=n('<p><strong>进一步提升资源利用率，难度也不断加大</strong></p><p>在不断提升资源利用率时，你会发现，这其中大部分的时间都必须<strong>跟内核打交道</strong>。</p><p>当将所有资源都合并到一起后，就会存在有机型代次差异的不同服务器硬件，<strong>而不同代次的机型，算力是不一样的</strong>，如果同一个工作负载的不同 Pod 位于不同代次的机器上，这就可能导致不同 Pod 的负载极其不均衡。</p><p>为了让业务更加充分地利用不同可用区域的资源，能够灵活地在不同可用区之间调度，甚至做到业务不感知可用区域的属性。**彻底屏蔽 K8s 节点、集群、可用区的概念，**分利用不同可用区的资源，同时让业务具备跨区域容灾能力。</p><h3 id="云原生路线图" tabindex="-1"><a class="header-anchor" href="#云原生路线图" aria-hidden="true">#</a> 云原生路线图</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212141827004.png" alt=""></p><h2 id="字节-3" tabindex="-1"><a class="header-anchor" href="#字节-3" aria-hidden="true">#</a> 字节<sup>[3]</sup></h2><h3 id="字节云原生推进历程" tabindex="-1"><a class="header-anchor" href="#字节云原生推进历程" aria-hidden="true">#</a> 字节云原生推进历程</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212142455658.png" alt=""></p><p><strong>2016 年：启动</strong> <strong>自研云引擎（TCE 平台）建设</strong> 。 它早期的定位是为内部应用提供快捷高效的服务部署方案，专注于<strong>服务的生命周期管理</strong>，如创建、升级、回滚、<strong>高可用、弹性扩展</strong>的容器服务，该阶段的宗旨是快速地支持研发效率、<strong>服务易迁移、可观测性</strong>等基础能力。</p><p><strong>2017 年：启动全面云原生化改造</strong> 。在这一阶段，我们完成了今日头条、抖音、西瓜视频等微服务的全量上容器，同时基于自研云平台基础，我们构建并完善了服务框架（Golang 为主）、<strong>Mesh 平台、流量平台、监控告警</strong>等基础设施。</p><p><strong>2018 年</strong> ：微服务架构升级。完成核心业务微服务迁移，并在 TCE 之上构建服务框架、Mesh、监控告警等基础设施；</p><p><strong>2019年：“推广搜”云原生化</strong> 。这一阶段对“推广搜”为主的物理机服务进行了容器化改造，完成了在线服务体系的全量上云。随着字节业务规模的扩展、业务种类的日趋繁多，集群的维护、稳定性、安全等受到了极大挑战，此阶段更关注集群的<strong>稳定性、容灾、抗风险等能力</strong>。</p><p><strong>2020 年：离线、存储云原生化</strong> 。我们推进了离在线混合部署，并且通过字节跳动自研融合调度器丰富在离线调度能力，进一步融合在离线业务体系，优化资源管控，提升了资源效率。</p><p>当实施离在线混合部署时，我们往往需要强大的调度器来实现离线业务和在线业务友好共存。事实上，公司早期发展阶段通常不具备完善的技术体系和能力，因此字节如何实现离在线混合部署也历经了一段演进路径，如下图所示：</p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212142815633.png" alt=""></p><p><strong>2021 年</strong> ：联邦化多集群演进。从资源多云到应用多云，实现全场景应用编排和资源管理的标准化和统一化。</p><p>目前基础架构的重点建设领域是 <strong>基于联邦化的多集群资源的统一管理和统一调度</strong> 。</p><h2 id="美团-4" tabindex="-1"><a class="header-anchor" href="#美团-4" aria-hidden="true">#</a> 美团<sup>[4]</sup></h2><h3 id="背景与现状" tabindex="-1"><a class="header-anchor" href="#背景与现状" aria-hidden="true">#</a> 背景与现状</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212153754330.png" alt=""></p><p>构建了以Kubernetes为核心的统一的资源管理系统</p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212153813509.png" alt=""></p><h3 id="openstack到kubernetes转变的障碍和收益" tabindex="-1"><a class="header-anchor" href="#openstack到kubernetes转变的障碍和收益" aria-hidden="true">#</a> OpenStack到Kubernetes转变的障碍和收益</h3><p>在OpenStack云平台时期，我们面临的主要问题包括以下几个方面：</p><ol><li><strong>架构复杂，运维和维护比较困难</strong>：OpenStack的整个架构中计算资源的管理模块是非常庞大和复杂，问题排查和可靠性一直是很大的问题。</li><li><strong>环境不一致问题突出</strong>：环境不一致问题是容器镜像出现之前业界的通用问题，不利于业务的快速上线和稳定性。</li><li><strong>虚拟化本身资源占用多</strong>：<strong>虚拟化本身大概占用10%的宿主机资源消耗，在集群规模足够大的时候</strong>，这是一块非常大的资源浪费。</li><li><strong>资源交付和回收周期长，不易灵活调配</strong>：一方面是整个虚拟机创建流程冗长；另一方面各种初始化和配置资源准备耗时长且容易出错，所以就导致整个机器资源从申请到交付周期长，快速的资源调配是个难题。</li><li><strong>高低峰明显，资源浪费严重</strong>：随着移动互联网的高速发展，公司业务出现高低峰的时间越来越多，为了保障服务稳定不得不按照最高的资源需求来准备资源，这就导致低峰时资源空闲严重，进而造成浪费。</li></ol><h3 id="风险控制和可靠性保障" tabindex="-1"><a class="header-anchor" href="#风险控制和可靠性保障" aria-hidden="true">#</a> 风险控制和可靠性保障</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212154039805.png" alt=""></p><h3 id="美团集群调度系统演变之路" tabindex="-1"><a class="header-anchor" href="#美团集群调度系统演变之路" aria-hidden="true">#</a> 美团集群调度系统演变之路</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212154323962.png" alt=""></p><h3 id="未来展望" tabindex="-1"><a class="header-anchor" href="#未来展望" aria-hidden="true">#</a> 未来展望</h3><blockquote><p>已过时，美团现在已经全面容器化</p></blockquote><ol><li>统一调度：VM会少量长期存在一段时间，但如果同时维护两套基础设施产品成本是非常高的，所以我们也在落地<strong>Kubernetes来统一管理VM和容器</strong>。</li><li>VPA：探索通过VPA来进一步提升整个资源的使用效率。</li><li>云原生应用管理：当前，我们已将云原生应用管理在生产环境落地，未来我们会进一步扩大云原生应用的覆盖面，不断提升研发效率。</li><li>云原生架构落地：<strong>推进各个中间件、存储系统、大数据以</strong>及搜索业务合作落地各个领域的云原生系统。</li></ol><h2 id="滴滴-5" tabindex="-1"><a class="header-anchor" href="#滴滴-5" aria-hidden="true">#</a> 滴滴<sup>[5]</sup></h2><h3 id="第一个阶段" tabindex="-1"><a class="header-anchor" href="#第一个阶段" aria-hidden="true">#</a> 第一个阶段</h3><p>2016 年，干了三个事情，<strong>容器编排引擎选型、 CI/CD 改造、监控平台配套升级</strong>。</p><p>在这个过程中，<strong>难就难在新老架构共存、兼顾用户使用习惯平滑过渡</strong>，我们在用户体验层面做了很多折中和优化，确保工程师们在使用的过程中不造反、不因为监控问题出现大故障，否则云原生之路就得戛然而止了。</p><p>在第一个阶段，一句话总结为：“<strong>平台起步，云原生技术选型和探索</strong>”。</p><h3 id="第二个阶段" tabindex="-1"><a class="header-anchor" href="#第二个阶段" aria-hidden="true">#</a> 第二个阶段</h3><p>2017 年 H2，接入“有影响力的试点业务”。过程中，不出所料，<strong>出现了大大小小各种故障</strong>，也因为平台体验过于反人类、不稳定、性能有缺陷，加上用户习惯很难被快速扭转，被用户们吐槽的不轻。<strong>幸运的是，都跨过去了</strong>。</p><p>在第二个阶段，一句话总结为：“<strong>业务接入，驱动技术升级</strong>”。</p><h3 id="第三个阶段" tabindex="-1"><a class="header-anchor" href="#第三个阶段" aria-hidden="true">#</a> 第三个阶段</h3><p>2019年开始，为了更充分发挥“云原生”的优势，开始落地在<strong>离线混部、推进中间件上云、全面搞服务治理、Auto-Scaling 能力开放、故障自动转移</strong>全面铺开等等，容器数量到达 10w。</p><p>总之，在这个阶段，反而是最平淡的一个阶段，所有的挑战都归结为技术问题。工程师们潜心钻研技术细节，研究各种奇技淫巧，死抠性能极限。</p><p>第三个阶段，一句话总结为：“<strong>在线业务全面接入，夯实云原生技术能力</strong>”。</p><h3 id="第四个阶段" tabindex="-1"><a class="header-anchor" href="#第四个阶段" aria-hidden="true">#</a> 第四个阶段</h3><p>2021年，收获的阶段，线上线下、研发测试交付全流程打通，业务全面接入，基础设施对研发和业务方透明，<strong>在离线统一调度</strong>，容器数量达到数十万。</p><p>混部作为一种业界通用的降本的手段，充满着非常多的技术挑战，总结如下：</p><ul><li>如何对业务进行合理的分级，不同级别的服务QoS如何定义</li><li>如何对业务进行精细化的画像，指导集群进行更合理的调度装箱，降低资源争抢的概率</li><li>单机如何进行内核层面的资源隔离策略，包括CPU、内存、IO、LLC cache、网络等资源，来保障高优业务的服务质量</li><li>单机如何进行性能干扰检测，指导单机驱逐和调度优化</li></ul><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212145557341.png" alt=""></p><h2 id="vivo-6" tabindex="-1"><a class="header-anchor" href="#vivo-6" aria-hidden="true">#</a> vivo<sup>[6]</sup></h2><h3 id="云原生价值分析" tabindex="-1"><a class="header-anchor" href="#云原生价值分析" aria-hidden="true">#</a> 云原生价值分析</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212150436155.png" alt=""></p><h3 id="探索和挑战" tabindex="-1"><a class="header-anchor" href="#探索和挑战" aria-hidden="true">#</a> 探索和挑战</h3><p><strong>试点探索</strong>：vivo云原生机器学习平台，成功为算法实现了降本、提效，让云原生和容器价值初露锋芒。</p><p><strong>战略升级</strong>：为了更好匹配战略落地，拥抱云原生，我们还对内部技术架构重新规划和升级，新增引入统一流量接入平台、容器运维管理平台、统一名字服务、容器监控等平台和能力，支撑容器生态在公司内部的全面建设和推广。</p><p><strong>集群挑战</strong>：<strong>集群规模快速增长</strong>、<strong>集群运维、运营和标准化</strong>、<strong>集群容器监控架构和可观测性</strong>、<strong>线上K8s版本升级迭代</strong>（需要实现给飞行的飞机换引擎）。</p><p><strong>平台挑战</strong>：<strong>容器IP的变化</strong>、<strong>周边生态的适配和兼容</strong>、<strong>用户使用习惯</strong>、<strong>价值输出</strong>。</p><h3 id="最佳实践" tabindex="-1"><a class="header-anchor" href="#最佳实践" aria-hidden="true">#</a> 最佳实践</h3><p><strong>容器集群高可用建设</strong></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212151051785.png" alt=""></p><p><strong>容器集群自动化运维</strong></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212151153343.png" alt=""></p><p><strong>容器平台架构升级</strong></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212151302815.png" alt=""></p><p><strong>容器平台能力增强</strong></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212151503184.png" alt=""></p><p><strong>产品能力矩阵完善</strong></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212151639188.png" alt=""></p><p><strong>实践总结</strong></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212151735225.png" alt=""></p><h3 id="对云原生的未来展望" tabindex="-1"><a class="header-anchor" href="#对云原生的未来展望" aria-hidden="true">#</a> 对云原生的未来展望</h3><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20241212152147724.png" alt=""></p><h2 id="ppt-汇总" tabindex="-1"><a class="header-anchor" href="#ppt-汇总" aria-hidden="true">#</a> PPT 汇总</h2><p>美团容器平台降本运营落地实践</p><p>美团大规模容器集群降本增效实践</p><p>快手关键混部技术介绍</p><p>快手 CPU&amp;GPU 超大规模在离线混部落地实践</p><p>快手 Kubernetes上的干扰检测和资源隔离增强的最佳实践</p><p>腾讯云原生降本增效最佳实践</p><p>腾讯如何管理超千万核资源的容器规模</p><p>小红书降本增效之路</p><p>小红书多集群打造面向混合云的高可用弹性架构</p><p>字节在 kubernetes 上构建一个精细化和智能化的资源管理系统</p><p>字节跳动云原生成本优化实践</p><p>字节如何将Kubernetes调度器的吞吐量提高数十倍</p><p>京东云跨集群大规模应用管理实践</p><p>网易云原生架构下中间件联邦高可用架构实践</p><p>vivo云原生容器探索和落地实践</p><p>vivo Kubernetes 集群无损升级实践</p><p>vivo服务端监控体系建设实践</p><p>阿里云云原生开放日</p><p>知乎在离线混部实践</p><p><strong>PPT 下载地址：</strong></p><p>链接: https://pan.baidu.com/s/1SHCZFvA-zKy7ptZI1jYitg 密码: 13qs</p><p>欢迎补充，交流学习~</p><blockquote><p>期待你在留言区和我讨论，也欢迎把这篇文章分享给你的同事、朋友。让我们一起在实战中演练，在交流中进步。 ——倪朋飞</p><p>期待你在下面留言 企业落地云原生的最佳实践相关文章，共同学习~</p></blockquote><p>以下每篇文章都值得仔细阅读。</p><p>参考资料：</p><p>[1] 云原生落地：https://clay-wangzhi.com/cloudnative/best-practice/containerization.html</p><p>​ 云原生实践总结：https://clay-wangzhi.com/cloudnative/</p><p>[2] 涉及数万人、历时三年，国内最大规模的云原生实践是如何打造出来的？：https://www.infoq.cn/article/91e8yfsbe71oum3iolaf</p><p>[3] 从混合部署到融合调度：字节跳动容器调度技术演进之路：https://developer.volcengine.com/articles/7317093690483638281</p><p>​ 字节跳动的云原生技术历程演进：https://developer.volcengine.com/articles/7317093834544906249</p><p>[4] Kubernetes如何改变美团的云基础设施？：https://tech.meituan.com/2020/08/13/openstack-to-kubernetes-in-meituan.html</p><p>​ 美团集群调度系统的云原生实践 https://tech.meituan.com/2022/02/17/kubernetes-cloudnative-practices.html</p><p>[5] 万字详解滴滴弹性云混部的落地历程：https://mp.weixin.qq.com/s/jcjAZUHGcydEe9CcO_EDZQ</p><p>​ 你们公司云原生转型持续了多长时间：https://mp.weixin.qq.com/s/k-2TVrY6oz_EZU8BhHgw1w</p><p>[6] vivo 云原生容器探索和落地实践：https://mp.weixin.qq.com/s/ux5z-EXmlN_2Qie6w9101g</p><p>我是 Clay，下期见 👋</p><hr><blockquote><ul><li><p>欢迎订阅我的公众号「SRE运维进阶之路」或关注我的 Github https://github.com/clay-wangzhi/SreGuide 查看最新文章</p></li><li><p>欢迎加我微信<code>sre-k8s-ai</code>，与我讨论云原生、稳定性相关内容</p></li></ul></blockquote><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/weixin-20240615194414355.png" alt="weixin" style="zoom:50%;">',113);function d(m,u){const t=e("ExternalLinkIcon");return p(),o("div",null,[g,s("p",null,[a("所有这些多集群编排能力都是基于腾讯云的 "),s("a",c,[a("Clusternet"),i(t)]),a(" 开源项目来建设。")]),l])}const f=r(h,[["render",d],["__file","cloud_native_industry_benchmark_and_implementation.html.vue"]]);export{f as default};
