import{_ as i}from"./plugin-vue_export-helper-c27b6911.js";import{r as c,o as t,c as n,a,b as e,d as r,e as o}from"./app-bdb4dd27.js";const p={},l=o('<h1 id="calico-异常重启问题复盘" tabindex="-1"><a class="header-anchor" href="#calico-异常重启问题复盘" aria-hidden="true">#</a> Calico 异常重启问题复盘</h1><blockquote><p>集群内网络架构为，基于Calico BGP 的路由模式，直接与交互机建联。</p></blockquote><h2 id="影响范围和故障时间线" tabindex="-1"><a class="header-anchor" href="#影响范围和故障时间线" aria-hidden="true">#</a> 影响范围和故障时间线</h2><p><strong>影响范围</strong></p><p>线下环境 node-xx 物理机上 Pod 网络不可用</p><p><strong>影响时间线（2023-07-23 22:09 ~ 22:14）</strong></p><p><strong>[22:13] 收到网工反馈 Peer Down</strong></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327201713521.png" alt="image-20240327201713521"></p><p><strong>[22:14] Calico 故障自愈（自动重启）</strong></p><h2 id="故障发生原因" tabindex="-1"><a class="header-anchor" href="#故障发生原因" aria-hidden="true">#</a> 故障发生原因</h2><h3 id="故障现象" tabindex="-1"><a class="header-anchor" href="#故障现象" aria-hidden="true">#</a> 故障现象</h3><p>1）查看 calico 事件信息：kubectl -n kube-system describe pod calico-node-xx <img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/calico1.png" alt=""></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/calico2.png" alt=""></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/calico3.png" alt=""></p><p>ok , 从上面事件日志可得找到以下关键信息：</p><p>Readiness probe failed、Liveness probe failed <strong>就绪探针、存活探针 探测失败</strong> → 查看探测方式，是使用 exec 进行探测（<strong>fork 新命令方式</strong>）→ 具体错误信息 <strong>Resource temporarily unavailable</strong></p><p>2）查看 kubelet 系统日志 journalctl -u kubelet.service --since &quot;2023-07-23 22:00:00&quot;</p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/calico4.png" alt=""></p><p>从上面日志可以得到以下关键信息： runtime: <strong>failed to create new OS thread</strong> (have 5 already; errno=11) runtime: may need to increase max user processes (ulimit -u) fatal error: newosproc</p><p>3）查看 Node-exporter 监控大盘，Processes 相关监控</p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/calico5.png" alt=""></p><p>从监控大盘可以分析出来：</p><p>从22点开始出现了<strong>大量的 Processes Forks</strong>， 没收集到 PIDs Number 和 Threads Number</p>',23),g={href:"https://github.com/google/cadvisor",target:"_blank",rel:"noopener noreferrer"},h=o('<p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327202617193.png" alt="image-20240327202617193"></p><p>查询到 22点多 容器<strong>总线程量达到 46k</strong></p><h3 id="根因分析" tabindex="-1"><a class="header-anchor" href="#根因分析" aria-hidden="true">#</a> 根因分析</h3><p>总结一下，上述现象的有用信息</p><ul><li>calico-node 使用 exec 进行监控探测，探测失败，Resource temporarily unavailable</li><li>kubelet 无法初始化线程，需要增加所处运行用户的进程限制，大致意思就是需要调整ulimit -u</li><li>22 点有大量的 process forks，node-xx <strong>容器总线程</strong> 突增到 46k，无法确定当时宿主机的总线程数，可以通过 如下命令实时计算 <code>ps -eLf | wc -l </code></li></ul><p>继续分析，登录服务查看 ulimit -u 的限制数 204k ，46k 比 204k 还差得远 <img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327203015642.png" alt="image-20240327203015642"></p><p>因为ulimit是针对于每用户而言的，具体还要验证每个用户的limit的配置，如下</p><p>根据以下配置判断，并没有超出设定的范围，最后的取值是会取 <code>/etc/security/limits.d/20-nofile.conf</code> 里面的值（优先级高） ，还是 204k <img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327203056629.png" alt="image-20240327203056629" style="zoom:50%;"></p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327203152448.png" alt="image-20240327203152448" style="zoom:50%;"><p>-→ 继续找 Google Resource temporarily unavailable 错误，翻阅linux内核文档，搜索PID相关字段，其中找到如下相关的PID参数 kernel.pid_max</p><p>https://www.kernel.org/doc/html/latest/admin-guide/sysctl/kernel.html#pid-max</p><blockquote><p>参数大致意思是，kernel允许当前系统分配的最大PID identify，如果kernel 在fork时hit到这个值时，kernel会wrap back到内核定义的minimum PID identify，意思就是不能分配大于该参数设定的值+1，该参数边界范围是全局的，属于系统全局边界</p></blockquote><p>同理，还有threads-max 参数</p><p>OK，安排，确认当前的 PID 限制，检查全局 PID 最大限制: cat /proc/sys/kernel/pid_max 49k，没错，应该就是它了，49k = 46k（容器总线程） + 非容器线程数</p><p>也检查下线程数限制：cat /proc/sys/kernel/threads-max 1545k</p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327203325829.png" alt="image-20240327203325829"></p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327203403343.png" alt="image-20240327203403343"></p><p><strong>结论：全局 PID（/proc/sys/kernel/pid_max ） 达到上限，导入 calico 无法 fork 进程，进而监控检查失败，存活探针自动重启</strong></p><p>等等，还没完，到底是谁把 PID 耗尽了呢，还要找出真凶，容器总线程 突增，说明是某个容器造成的，安排promql 查，container_threads{node=&quot;node-xx&quot;} <img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327203548494.png" alt="image-20240327203548494"></p><p>至此，结案了，联系开发改代码，有线程泄露。</p><h2 id="why-分析" tabindex="-1"><a class="header-anchor" href="#why-分析" aria-hidden="true">#</a> Why 分析</h2><p>1）导致问题的直接原因是什么？</p><p>Xxx 应用线程泄露，导致全局 PID 耗尽，进而导致 calico 监控检查失败，自动重启。</p><p>2）K8s Pod 中没有限制 PID 数吗？</p><p>默认 K8s Pod 是不对 PID 数进行限制的。</p><p><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/image-20240327203835125.png" alt="image-20240327203835125"></p><p>3）为何排查问题耗时较长？</p><p>未收集物理机 Processes 的相关监控指标，也未设置 PID 使用百分比触发器</p><p>4）全局PID限制，为何比用户PID限制要小？</p><p>参数设置不合理，未进行调优</p><h2 id="后续-todo" tabindex="-1"><a class="header-anchor" href="#后续-todo" aria-hidden="true">#</a> 后续 TODO</h2><p>1）调整 pid_max 参数</p><p>2）开启 Node-exporter Process 监控并补全告警</p><p>​ node-exporter 启动参数中新增 <code> --collector.processes</code>，并添加告警规则 <code>(node_processes_threads / on(instance) min by(instance) (node_processes_max_processes or node_processes_max_threads) &gt; 0.8)</code></p><p>3）评估业务是否需要开始 Pod PID 限制：https://kubernetes.io/zh-cn/docs/concepts/policy/pid-limiting/</p><p>我是 Clay，下期见 👋</p><hr><blockquote><ul><li><p>欢迎订阅我的公众号「SRE运维进阶之路」或关注我的 Github https://github.com/clay-wangzhi/wiki 查看最新文章</p></li><li><p>欢迎加我微信<code>sre-k8s-ai</code>，与我讨论云原生、稳定性相关内容</p></li></ul></blockquote><img src="https://clay-blog.oss-cn-shanghai.aliyuncs.com/img/weixin.png" alt="weixin" style="zoom:50%;">',39);function m(d,u){const s=c("ExternalLinkIcon");return t(),n("div",null,[l,a("p",null,[e("4）有没有可能是 PID 跑满了，由于没有收集到 PIDs Number 和 Threads Number，所以换个思路，看看容器 "),a("a",g,[e("cadvisor"),r(s)]),e(' 是否有收集 Processes 相关信息，是不是容器捣的鬼，使用 promql 查询 node-xx 容器线程趋势 sum(container_threads{node="node-xx"})')]),h])}const k=i(p,[["render",m],["__file","calico-restart.html.vue"]]);export{k as default};
